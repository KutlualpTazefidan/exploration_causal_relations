{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxuser/spiced-academy/data_science_capstone/exploration_causal_relations/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flair.datasets import ColumnCorpus # Used to load and preprocess text data for NLP tasks\n",
    "from flair.embeddings import FlairEmbeddings # Representations of words in vector form\n",
    "from flair.embeddings import CharacterEmbeddings # Representations of words in vector form\n",
    "from flair.embeddings import TokenEmbeddings # Representations of words in vector form\n",
    "from flair.embeddings import StackedEmbeddings # Representations of words in vector form\n",
    "from flair.models import SequenceTagger # sequence tagging, NER or POS\n",
    "from flair.trainers import ModelTrainer # Training Flair models\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SPOTTING_DATASET = \"../../data/concept-spotting/sentences/\"\n",
    "PATH_FLAIR_FOLDER = \"../../data/flair-models/sentences/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-Spotter: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # For reproducibility\n",
    "    # (https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True # cuDNN operations will produce the same results on the GPU across runs\n",
    "    torch.backends.cudnn.benchmark = False #  When enabled, cuDNN may dynamically choose the best algorithm for convolution operations, which can result in slightly different numerical results across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-07 14:26:07,700 Reading data from ../../data/concept-spotting/sentences\n",
      "2023-10-07 14:26:07,701 Train: ../../data/concept-spotting/sentences/train.txt\n",
      "2023-10-07 14:26:07,705 Dev: ../../data/concept-spotting/sentences/dev.txt\n",
      "2023-10-07 14:26:07,707 Test: ../../data/concept-spotting/sentences/test.txt\n",
      "Corpus: 583 train + 127 dev + 122 test sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14065/1214949526.py:7: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
      "  tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type) # Storing the tags/bio-chunks\n"
     ]
    }
   ],
   "source": [
    "# data preperation for NLP, defning the structure of the dataset, type of tagging, dictionary for tags\n",
    "# Mapping column indices (0, 1, 2) to column names ('text', 'pos', 'chunk_BIO'), the structure of the data set\n",
    "# text, part of speech, containing BIO (Begin,Inside,Outside) - beginning, inside and end of the sentence\n",
    "columns = {0: 'text', 1: 'pos', 2: 'chunk_BIO'} \n",
    "tag_type = \"chunk_BIO\"\n",
    "corpus = ColumnCorpus(PATH_SPOTTING_DATASET, columns) # \n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type) # Storing the tags/bio-chunks\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-07 14:26:09,697 SequenceTagger predicts: Dictionary with 3 tags: O, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "# defining a list of embeddings to be used in the model\n",
    "# CharacterEmbeddings : characters in the word, capturing subword information\n",
    "# FlairEmbeddings : pretrained contextual embeddings - based on forward & backward pass LM trained on news\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    CharacterEmbeddings(), \n",
    "    FlairEmbeddings('news-forward'), \n",
    "    FlairEmbeddings('news-backward')]\n",
    "\n",
    "# Stacking the embeddings types created before.\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "set_seed(42)\n",
    "\n",
    "# Extracting important parts of sentences\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=64,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True,\n",
    "                                        dropout=0.25,\n",
    "                                        rnn_layers=2)\n",
    "set_seed(42)\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-07 14:36:27,974 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:27,978 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): CharacterEmbeddings(\n",
      "      (char_embedding): Embedding(275, 25)\n",
      "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4146, out_features=4146, bias=True)\n",
      "  (rnn): LSTM(4146, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (linear): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2023-10-07 14:36:27,981 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:27,984 Corpus: \"Corpus: 583 train + 127 dev + 122 test sentences\"\n",
      "2023-10-07 14:36:27,990 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:27,992 Parameters:\n",
      "2023-10-07 14:36:27,994  - learning_rate: \"0.200000\"\n",
      "2023-10-07 14:36:27,998  - mini_batch_size: \"32\"\n",
      "2023-10-07 14:36:28,001  - patience: \"3\"\n",
      "2023-10-07 14:36:28,004  - anneal_factor: \"0.5\"\n",
      "2023-10-07 14:36:28,006  - max_epochs: \"20\"\n",
      "2023-10-07 14:36:28,008  - shuffle: \"True\"\n",
      "2023-10-07 14:36:28,012  - train_with_dev: \"False\"\n",
      "2023-10-07 14:36:28,014  - batch_growth_annealing: \"False\"\n",
      "2023-10-07 14:36:28,017 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:28,020 Model training base path: \"../../data/flair-models/sentences\"\n",
      "2023-10-07 14:36:28,023 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:28,025 Device: cpu\n",
      "2023-10-07 14:36:28,028 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:28,036 Embeddings storage mode: cpu\n",
      "2023-10-07 14:36:28,039 ----------------------------------------------------------------------------------------------------\n",
      "2023-10-07 14:36:46,747 epoch 1 - iter 1/19 - loss 0.00000002 - time (sec): 18.70 - samples/sec: 43.84 - lr: 0.200000\n",
      "2023-10-07 14:37:15,511 epoch 1 - iter 2/19 - loss 0.00000000 - time (sec): 47.47 - samples/sec: 39.06 - lr: 0.200000\n",
      "2023-10-07 14:37:34,259 epoch 1 - iter 3/19 - loss 0.00000001 - time (sec): 66.22 - samples/sec: 42.68 - lr: 0.200000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "result = trainer.train(PATH_FLAIR_FOLDER,\n",
    "                       learning_rate=0.2,\n",
    "                       mini_batch_size=32,\n",
    "                       max_epochs=20,\n",
    "                       shuffle=True,\n",
    "                       num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert result['test_score'] == 0.6466"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
